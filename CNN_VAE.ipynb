{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/FOBM2asRvPh+3UZPvO+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natrask/ENM5310/blob/main/CNN_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm adopting here the [tensorflow tutorial for CNN VAEs](https://www.tensorflow.org/tutorials/generative/cvae) stripping out as much of the extra code as possible so we can focus just on how to construct the ELBO loss function and see the essential ingredients."
      ],
      "metadata": {
        "id": "MP96fhyLI_Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse.linalg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.reset_default_graph()\n",
        "config = tf.ConfigProto()\n",
        "sess = tf.Session(config=config)"
      ],
      "metadata": {
        "id": "_woU4wppOeY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7a2558-4d2f-493b-ef69-4b5618bbb3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the MNIST dataset consisting of a bunch of handwritten digits"
      ],
      "metadata": {
        "id": "v-_7Ce5Vq9zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "metadata": {
        "id": "plL3gup8q1G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Break the dataset into a pile of test and training data"
      ],
      "metadata": {
        "id": "PMFVvWrhrGGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build up the encoder architecture, using the reparameterization trick to generate a sample from the posterior distribution"
      ],
      "metadata": {
        "id": "G951L72krPoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "npix1d = 28\n",
        "Nbatch = 1\n",
        "input_img = tf.placeholder(dtype=tf.float32,shape=(Nbatch,npix1d,npix1d))\n",
        "encoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            # No activation\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "        ])\n",
        "decoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            # No activation\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
        "        ])\n",
        "\n",
        "#Now sample from the encoder to get Z, and decode to get Xhat\n",
        "mu_q, logvar_q = tf.split(encoder(tf.expand_dims(input_img,-1)), num_or_size_splits=2, axis=1)\n",
        "eps = tf.random.normal(shape=mu_q.shape)\n",
        "Zsample = eps * tf.exp(logvar_q * .5) + mu_q\n",
        "Xhat = decoder(Zsample)"
      ],
      "metadata": {
        "id": "x1zXmeXorWcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build ELBO loss function"
      ],
      "metadata": {
        "id": "1_1KeTcMvpQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        "cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=Xhat, labels=tf.expand_dims(input_img,-1))\n",
        "logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "logpz = log_normal_pdf(Zsample, 0., 0.)\n",
        "logqz_x = log_normal_pdf(Zsample, mu_q, logvar_q)\n",
        "\n",
        "LOSS = -tf.reduce_mean(logpx_z + logpz - logqz_x)"
      ],
      "metadata": {
        "id": "c4XCufi4v91n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}